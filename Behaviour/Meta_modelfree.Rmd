---
title: "Meta_modelfree"
output: html_document
date: "2024-10-23"
---
### Information
The script used the data from Jenna (food, social, temporal discounting) and Yang et al., 2022 (clothing). Since the script relies on the data organized by other scripts (e.g., Behaviour/A_Preprocess.Rmd), WE HAVE TO RERUN THIS SCRIPT if any change in those files is made. 

** RERUN THIS SCRIPT if any change in Behaviour/A_Preprocess.Rmd is made. 

### Inputs and Variables
```{r}
# Inputs: 
# ../data/fromYang2022/Brand_Data_Clean.RData"
# ../data/food_modeling_data.RData
# ../data/social_modeling_data.RData
# ../data/discounting_modeling_data.RData

# Outputs:
# ../data/Clothing_data.RData
# ../data/datasets.RData (this is the one contains all datasets from the sated condition)
```

### 1. Preparations
```{r}
#clear working environment
rm(list=ls())

#clear all plots
if(!is.null(dev.list())) dev.off()

#load required libraries
library(readxl)
library(ggpubr)
library(rstatix)
library(readr)
library(tidyr)
library(dplyr)
library(zoo)
library (ggplot2)
library(tibble)
library(rstatix)
library(tidyverse)
library(ez) #
library(lme4)
library(lmerTest)

```

### 2. Load Data 
#### 2.1 Food, Social, Discount (sated condition only)
```{r, message=FALSE, warning=FALSE, echo=FALSE}
# List of RData file names
filelist <- c("food_modeling_data.RData","social_modeling_data.RData", "discount_modeling_data.RData")

# Loop through each RData file
for (file in filelist) {
  
  # Load the RData file
  load(paste0("../data/", file))
  
  # Get all objects in the current environment
  loaded_objects <- ls()
  
  # Find the object that matches the pattern "data_*_sated"
  sated_object_name <- grep("data_.", loaded_objects, value = TRUE)
  # Remove any objects that contain "_long"
  sated_object_name <- sated_object_name[!grepl("_long", sated_object_name)]
  sated_object_name <- sated_object_name[!grepl("_combined", sated_object_name)]
}

#initialize data
org_data_food_sated <- tibble(); org_data_food_hungry <- tibble()
org_data_social_sated <- tibble(); org_data_social_hungry <- tibble()
org_data_discount_sated <- tibble(); org_data_discount_hungry <- tibble()

# start rearrange data so that different datasets have the same variable names
for (datafile in sated_object_name) {
  rm(trial_data)
  rm(tempData)
  trial_data <- get(datafile)
  # keep useful variables
  tempData <- trial_data %>% select(subject, RT, choice) #subject, RT, response
  
  if (grepl("neu", datafile)) { 
    upleft_fix <- trial_data$foodleft_fix # food
    upright_fix <- trial_data$foodright_fix # food
    downleft_fix <- trial_data$nutrileft_fix # nutrition
    downright_fix <- trial_data$nutriright_fix # nutrition
    upleft_time <- trial_data$foodleft_time
    upright_time <- trial_data$foodright_time
    downleft_time <- trial_data$nutrileft_time
    downright_time <- trial_data$nutriright_time
    upleft_val <- trial_data$taste_left
    upright_val <- trial_data$taste_right
    downleft_val <- trial_data$health_left
    downright_val <- trial_data$health_right
  } else if (grepl("social", datafile)) { 
    upleft_fix <- trial_data$selfleft_fix # self
    upright_fix <- trial_data$selfright_fix # self
    downleft_fix <- trial_data$ngoleft_fix # ngo
    downright_fix <- trial_data$ngoright_fix # ngo
    upleft_time <- trial_data$selfleft_time
    upright_time <- trial_data$selfright_time
    downleft_time <- trial_data$ngoleft_time
    downright_time <- trial_data$ngoright_time
    upleft_val <- trial_data$self_left
    upright_val <- trial_data$self_right
    downleft_val <- trial_data$ngo_left
    downright_val <- trial_data$ngo_right
  } else if (grepl("discount", datafile)) {
    upleft_fix <- trial_data$timeleft_fix # amount
    upright_fix <- trial_data$timeright_fix # amount
    downleft_fix <- trial_data$valueleft_fix # delay
    downright_fix <- trial_data$valueright_fix # delay
    upleft_time <- trial_data$valueleft_time
    upright_time <- trial_data$valueright_time
    downleft_time <- trial_data$timeleft_time
    downright_time <- trial_data$timeright_time
    upleft_val <- trial_data$value_left
    upright_val <- trial_data$value_right
    downleft_val <- trial_data$time_left
    downright_val <- trial_data$time_right
  }
  
  # Create a new row as a data frame
  new_row <- data.frame(
    upleft_val = upleft_val, 
    upright_val = upright_val, 
    downleft_val = downleft_val, 
    downright_val = downright_val,
    response = as.numeric(trial_data$response == "left"), #1: left; 0: right
    upleft_fix = upleft_fix,
    upright_fix = upright_fix,
    downleft_fix = downleft_fix,
    downright_fix = downright_fix,
    upleft_time = upleft_time,
    upright_time = upright_time,
    downleft_time = downleft_time,
    downright_time = downright_time,
    stringsAsFactors = FALSE  # Ensure character variables are not converted to factors
  )
  trial_data <- cbind(tempData, new_row)
  
  # store the data to corresponding task/condition
  if (grepl("_neu", datafile) & grepl("sated", datafile)) {
    org_data_food_sated <- trial_data
  } else if  (grepl("_neu", datafile) & grepl("hungry", datafile)) {
    org_data_food_hungry <- trial_data
  } else if (grepl("social", datafile) & grepl("sated", datafile)) {
    org_data_social_sated <- trial_data
  } else if  (grepl("social", datafile) & grepl("hungry", datafile)) {
    org_data_social_hungry <- trial_data
  } else if  (grepl("discount", datafile) & grepl("sated", datafile)) {
    org_data_discount_sated <- trial_data
  } else if  (grepl("discount", datafile) & grepl("hungry", datafile)) {
    org_data_discount_hungry <- trial_data
  } 
}
```
#### 2.2 Clothing
```{r, message=FALSE, warning=FALSE, echo=FALSE}
# data from https://osf.io/d7s6c/ and https://osf.io/f2urs/
# Upleftval/ uprightval/ downleftval/downrightval: preferential ratings of the options at different positions
# ROI: currently gazed location (1: upper left 2: upper right 3: down left 4: down right). 
# NOTE: 
#   choice: left option is chosen (0 or 1)
#   coding: up: cloth's rating; down: brand's rank (20 levels)

# Load data
# data_raw_clothing <- read.csv("../data/moneyrisk.csv") 
load("../data/fromYang2022/Brand_Data_Clean.RData")

# Create empty dataframes for each category
data_clothing <- tibble()

# Read in data for all participants in all conditions
# summarize the dwell time for each attribute in each trial (so far the fixation times are stored separately within a trial)
subjlist <- seq_along(brand_present_sub)
for (subject in subjlist) {
  # Get the subject number from the file name
  subdata <- brand_present_sub[[subject]]
  Ntrial <- sum(subdata$fixnum == 1)
  # Identify indices where fixnum == 1
  indices <- which(subdata$fixnum == 1)
  
  # Create a sequence of labels (1, 2, 3, etc.) of the same length as identified indices
  labels <- seq_along(indices)
  
  # Assign these labels to a new column 'fixation_label'
  subdata$trial <- NA  # Create a new column initialized with NA
  subdata$trial[indices] <- labels  # Assign labels to the identified rows
  
  for (t in 1:Ntrial) {
    if (t<Ntrial) {
      trial_start <- which(subdata$trial == t)
      trial_end <- which(subdata$trial == (t+1))-1
    } else {
      trial_start <- which(subdata$trial == t)
      trial_end <- nrow(subdata)
    }
    trial_data <- subdata[trial_start:trial_end, ]
    Nfix <-  unique(trial_data$fixnum)
    
    #list of variables
    # note: ROI: currently gazed location (1: upper left 2: upper right 3: down left 4: down right). 
    upleft_fix <- sum(trial_data$roi == 1) # cloth's rating
    upright_fix <- sum(trial_data$roi == 2)  # cloth's rating
    downleft_fix <- sum(trial_data$roi == 3) # brand's rank
    downright_fix <- sum(trial_data$roi == 4) # brand's rank 
    upleft_time <- sum(trial_data$fixdur[trial_data$roi == 1])
    upright_time <- sum(trial_data$fixdur[trial_data$roi == 2])
    downleft_time <- sum(trial_data$fixdur[trial_data$roi == 3])
    downright_time <- sum(trial_data$fixdur[trial_data$roi == 4])
    upleft_val <- trial_data$upleftval[1]
    upright_val <- trial_data$uprightval[1]
    downleft_val <- trial_data$downleftval[1]
    downright_val <- trial_data$downrightval[1]
    
    
    # Create a new row as a data frame
    new_row <- data.frame(
      subject = subject,
      trial = t,
      upleft_val = upleft_val, # cloth's rating
      upright_val = upright_val, # cloth's rating
      downleft_val = downleft_val, # brand's rank
      downright_val = downright_val, # brand's rank
      response = trial_data$choice[1], #1: left; 0: right
      RT =  trial_data$rt[1],
      upleft_fix = upleft_fix,
      upright_fix = upright_fix,
      downleft_fix = downleft_fix,
      downright_fix = downright_fix,
      upleft_time = upleft_time,
      upright_time = upright_time,
      downleft_time = downleft_time,
      downright_time = downright_time,
      stringsAsFactors = FALSE  # Ensure character variables are not converted to factors
    )
    data_clothing <- rbind(data_clothing, new_row)
  }
}
```

### 3. Add additional info to  dataframes
Include:
- Value differences
- dwell time difference
- zscored dwell difference for each subjects
- proportion of dwell time

```{r}
add_variables <- function(data, data_name){
  # inclusion criteria
  validT <- data$RT > 250 & is.na(data$RT) == 0
  data <- data[validT, ]

  
  # dwell difference (left vs. right)
  data$up_dwelldiff <- data$upleft_time - data$upright_time
  data$down_dwelldiff <- data$downleft_time - data$downright_time
  
  # proportion of dwell time
  allfixtime <- data$upleft_time + data$upright_time + data$downleft_time + data$downright_time
  data$fixProp1 <- data$upleft_time/allfixtime
  data$fixProp2 <- data$upright_time/allfixtime
  data$fixProp3 <- data$downleft_time/allfixtime
  data$fixProp4 <- data$downright_time/allfixtime
  data$up_fixpropdiff <- data$fixProp1 - data$fixProp2 #(left vs. right)
  data$down_fixpropdiff <- data$fixProp3 - data$fixProp4 #(left vs. right)
  
    # more information for model-based analysis
    chooseR <- data$response == 0
    data$RT_right <- data$RT
    data$RT_right[chooseR] <- data$RT_right[chooseR]*-1
    if (grepl("hungry", data_name, ignore.case = TRUE)) {
      data$H <- rep(1,length(data$RT))
    } else {
      data$H <- rep(0,length(data$RT))
    }
    
    # Rescale att. to range from 1 to 10
    data$scl_upleft_val <- 1 + (data$upleft_val - min(data$upleft_val)) * (10 - 1) / (max(data$upleft_val) - min(data$upleft_val))
    data$scl_upright_val <- 1 + (data$upright_val - min(data$upright_val)) * (10 - 1) / (max(data$upright_val) - min(data$upright_val))
    data$scl_downleft_val <- 1 + (data$downleft_val - min(data$downleft_val)) * (10 - 1) / (max(data$downleft_val) - min(data$downleft_val))
    data$scl_downright_val <- 1 + (data$downright_val - min(data$downright_val)) * (10 - 1) / (max(data$downright_val) - min(data$downright_val))
    
  # reverse the value for time 
    if (grepl("discount", data_name, ignore.case = TRUE)) {
      data$scl_downleft_val <- 10-data$scl_downleft_val
      data$scl_downright_val <- 10-data$scl_downright_val
    }
      
    # vd of each attribute (left vs. right)
  data$up_vd <- data$scl_upleft_val - data$scl_upright_val
  data$down_vd <- data$scl_downleft_val - data$scl_downright_val
  
  # Initialize z_data
  z_data <- tibble()
  count <- 0
  # Get unique subjects
  subjlist <- unique(data$subject)
  for (s in subjlist){
    # Create a subset for the current subject
    subjdata <- data[data$subject == s, ]
    
    # relabel subject numbers from 1 to N
    count <- count +1
    subjdata$P_subj <- rep(count,length(subjdata$RT))
    
    # Calculate z-scores for each variable
    subjdata$z_up_vd <- scale(subjdata$up_vd)[, 1]
    subjdata$z_down_vd <- scale(subjdata$down_vd)[, 1]
    subjdata$z_up_dwelldiff <- scale(subjdata$up_dwelldiff)[, 1]
    subjdata$z_down_dwelldiff <- scale(subjdata$down_dwelldiff)[, 1]
    subjdata$z_up_fixpropdiff <- scale(subjdata$up_fixpropdiff)[, 1]
    subjdata$z_down_fixpropdiff <- scale(subjdata$down_fixpropdiff)[, 1]
    z_data <- rbind(z_data, subjdata)
  }
  return(z_data)
}

# List of dataset names
dataset_names <- c("org_data_food_sated", "org_data_food_hungry", "org_data_social_sated", "org_data_social_hungry", "org_data_discount_sated", "org_data_discount_hungry", "data_clothing")

# Loop through the datasets and apply the add_variables function
for (name in dataset_names) {
  assign(name, add_variables(get(name), name))
}

# Save the modified datasets
save(org_data_food_sated, org_data_food_hungry, org_data_social_sated, org_data_social_hungry, org_data_discount_sated, org_data_discount_hungry, data_clothing, file = "../data/datasets.RData")
```

### 4 desciptive results
[add descriptions]
```{r}
# clean the environment and load the organized data again
rm(list=ls())
load("../data/datasets.RData")

# group means based on subject, choice, fixation time (upper attribute), fixation time (lower attribute)
calculate_mean <- function(data){
  results <- data %>%
    group_by(subject) %>%
    summarise(
      mean_rt = mean(RT, na.rm = TRUE),       # Mean of 'rt'
      mean_choice = mean(response, na.rm = TRUE),  # Mean of 'choice'
      mean_dwellup = mean(fixProp1+fixProp2, na.rm = TRUE),
      mean_dwelldown = mean(fixProp3+fixProp4, na.rm = TRUE),
      mean_upfixPropdiff = mean(up_fixpropdiff, na.rm = TRUE),  # Mean of 'choice'
      mean_downfixPropdiff = mean(down_fixpropdiff, na.rm = TRUE),       # Mean of 'rt'
      #mean_choice = mean(choice, na.rm = TRUE)  # Mean of 'choice'
    )
  return(results)
}

# Create a list of your datasets
datasets <- list(data_clothing = data_clothing, 
                 data_food_sated = org_data_food_sated,
                 data_food_hungry = org_data_food_hungry,
                 data_social_sated = org_data_social_sated,
                 data_social_hungry = org_data_social_hungry, 
                 data_discount_sated = org_data_discount_sated,
                 data_discount_hungry = org_data_discount_hungry)

# Initialize an empty list to store the results
mean_data_list <- list()

# Loop through each dataset in the list
count <- 0
mean_of_mean <- matrix(data = NA, nrow = length(names(datasets)), ncol = 7)
for (name in names(datasets)) {
  count <- count +1
  # Compute the mean for the current dataset
  mean_data_list[[name]] <- calculate_mean(datasets[[name]])
  subdata <- mean_data_list[[name]] 
  mean_of_mean[count, 1] <- name  # Store the dataset name
  mean_of_mean[count, 2] <- mean(subdata$mean_rt)
  mean_of_mean[count, 3] <- mean(subdata$mean_choice)
  mean_of_mean[count, 4] <- mean(subdata$mean_dwellup)
  mean_of_mean[count, 5] <- mean(subdata$mean_dwelldown)
  mean_of_mean[count, 6] <- mean(subdata$mean_upfixPropdiff)
  mean_of_mean[count, 7] <- mean(subdata$mean_downfixPropdiff)
}
```

### 5 GLMM
[add descriptions]
```{r}
rm(data_interested)
data_interested <- list("data_clothing", "org_data_food_sated", "org_data_food_hungry", "org_data_social_sated", "org_data_social_hungry","org_data_discount_sated", "org_data_discount_hungry")

# Define the models as a list of formulas
model_formulas <- list(
  model1 = response ~ z_up_vd + z_down_vd + (1 | subject),
  model2 = response ~ z_up_vd + z_down_vd + z_up_fixpropdiff + (1 | subject),
  model3 = response ~ z_up_vd + z_down_vd + z_down_fixpropdiff + (1 | subject),
  model4 = response ~ z_up_vd + z_down_vd + z_up_fixpropdiff + z_down_fixpropdiff + (1 | subject)
)

# Initialize a list to store all glm results by dataset and model type
glm_results <- list()

# Initialize an empty list to store AIC results
aic_results <- data.frame(dataset = character(), model = character(), aic = numeric(), stringsAsFactors = FALSE)

# Setting global options to mute specific warnings
options(lme4.warnOnlyOnce = FALSE)   # Muting warning repeats

# Loop through each dataset
for (data_name in data_interested) {
  # Retrieve the dataset using `get`
  dataset <- get(data_name)
  dataset <- dataset[dataset$up_dwelldiff >0 | dataset$down_dwelldiff >0, ]
  
  # Initialize a sublist for the current dataset
  glm_results[[data_name]] <- list()
  
  # Loop through each model formula
  for (model_name in names(model_formulas)) {
    formula <- model_formulas[[model_name]]
    
    # Run the GLM model and store the result
    glm_results[[data_name]][[model_name]] <- glmer(
      formula,
      data = dataset,
      family = binomial(link = "logit"),
      control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 5e5))
    )
    
    # Extract the AIC value
    aic_value <- AIC(glm_results[[data_name]][[model_name]])
    
    # Append the AIC value to the results data frame
    aic_results <- rbind(aic_results, data.frame(dataset = data_name, model = model_name, aic = aic_value))
  }
}
  
# aic_results suggest that model4 is the best model to explain choice for all datasets!
```


### 6 attribute weight and dwell-time allocation
```{r}
# List of datasets of interest
data_interested <- list("data_clothing", "org_data_food_sated", "org_data_social_sated","org_data_discount_sated")
# Initialize an empty data frame to store coefficient summaries
coef_summary <- data.frame(dataset = character(), term = character(), estimate = numeric(), std_error = numeric(), z_value = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each dataset in data_interested
for (data_name in data_interested) {
  # Check if model4 exists in the glm_results for the dataset
  if ("model4" %in% names(glm_results[[data_name]])) {
    model <- glm_results[[data_name]][["model4"]]
    
    # Extract the summary of model4
    model_summary <- summary(model)
    
    # Get coefficient estimates and standard errors
    coef_data <- data.frame(
      dataset = data_name,
      term = rownames(model_summary$coefficients),
      estimate = model_summary$coefficients[, "Estimate"],
      std_error = model_summary$coefficients[, "Std. Error"],
      z_value = model_summary$coefficients[, "z value"],
      p_value = model_summary$coefficients[, "Pr(>|z|)"]
    )
    
    # Append the coefficient data to the summary data frame
    coef_summary <- rbind(coef_summary, coef_data)
  } else {
    message(paste("Model4 not found for dataset:", data_name))
  }
}

# Print the coefficient summary
print(coef_summary)
```

# 7 organize data for the modeling
```{r}
#loop over subjects to get the data and arrange it in the order needed
# function to create tables for model-based analysis
fittingDDMs <- function(data_name){
  
  # load data
  data <- data
# Check if "clothing" is in the name
if (grepl("clothing", data_name, ignore.case = TRUE)) {
  combineData <- "False"
  cond <- 1
} else {
  combineData <- "True"
  cond <- c(1,2) 
}

uID <- unique(data$subject)
# attributeA and B (cloth: A = cloth, B = brand; food: A= food, B = neutrition; Social: A= self, B= ngo; Discount: A= value, B = time)
upA <- c() 
upB <- c() 
downA <- c() 
downB <- c()

fixProp_upA <- c() 
fixProp_upB <- c() 
fixProp_downA <- c() 
fixProp_downA <- c() 
RT <- c() # in milli-second or second

H <- c() #whether trial is hungry (1) or sated (0); not needed for clothing data
P <- c() #participant number (from 1 till nsubj, so 1, 2, 3, 4, ..., nsubj)

blubb <- matrix(NA,nrow=max(uID),ncol=2) # check if fixation props are correct
dt <- 1/1000 # are you sure

for (s in (unique(data$subject))){
  
  #loop over sessions (1 = hungry)
  for (t in cond){
    if (t == 1){ #session-specific stuff up front
      sub <- data[data_discount_hungry$subject == s, ] #hungry
      fixatedElement <- expanded_table_h[[which(unique(data_discount_hungry$subject)==s)]]
    } else {
      sub <- data_discount_sated[data_discount_sated$subject == s, ] #sated
      fixatedElement <- expanded_table_s[[which(unique(data_discount_sated$subject)==s)]]
    }
    
    #rearrange input data for value -time Choice
    valueL <- (sub$value_left<sub$value_right) #whether impatient choice was left
    response <- sub$response
    response <- as.numeric(((response==("left"))&(valueL==T))|((response==("right"))&(valueL==F)))
    rt_s <- sub$RT*dt
    rt_s[response==0] = -rt_s[response==0] #dwiener function in JAGS wants "negative" rt if choice == 0
    
    valueA_s <- sub$value_left*(valueL==T)+sub$value_right*(valueL==F)
    valueB_s <- sub$value_left*(valueL==F)+sub$value_right*(valueL==T)
    timeA_s <- sub$time_left*(valueL==T)+sub$time_right*(valueL==F)
    timeB_s <- sub$time_left*(valueL==F)+sub$time_right*(valueL==T)
    
    #prepare fixation data value - time
    ntrialsi <- nrow(sub)
    fixProps <- matrix(nrow = ntrialsi,ncol = 4)
    for (n in 1:ntrialsi){
      fEn <- fixatedElement[1:round(sub$RT[n]),n] #stream of fixated elements in current trials
      fixProps[n,] <- c(sum(na.omit(fEn==1)),sum(na.omit(fEn==2)),sum(na.omit(fEn==3)),sum(na.omit(fEn==4)))/sum(na.omit(fEn>=1))
    }
    fixProps <- matrix(c(fixProps[,1]*(valueL==T)+fixProps[,2]*(valueL==F),fixProps[,1]*(valueL==F)+fixProps[,2]*(valueL==T),
                         fixProps[,3]*(valueL==T)+fixProps[,4]*(valueL==F),fixProps[,3]*(valueL==F)+fixProps[,4]*(valueL==T)),ncol=4)
    
    
    #fill in "all-subject" vectors for value time
    valueA <- c(valueA,valueA_s)
    valueB <- c(valueB,valueB_s)
    timeA <- c(timeA,timeA_s)
    timeB <- c(timeB,timeB_s)
    
    fixProp1 <- c(fixProp1,fixProps[,1])
    fixProp2 <- c(fixProp2,fixProps[,2])
    fixProp3 <- c(fixProp3,fixProps[,3])
    fixProp4 <- c(fixProp4,fixProps[,4])
    RT <- c(RT,rt_s)
    H <- c(H,rep(t==1,length(rt_s)))
    P <- c(P,rep(which(uID==s),length(rt_s)))
    
    
  }
}

# List of datasets of interest
data_interested <- list("data_clothing", "org_data_food_sated", "org_data_social_sated","org_data_discount_sated")
for (data_name in data_interested) {

  }  
```